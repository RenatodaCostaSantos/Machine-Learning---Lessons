{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4t0B5YuTigryOugr5ajlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenatodaCostaSantos/Machine-Learning---Lessons/blob/main/Supervised%20ML/Logistic%20regression/Logistic_regression_lesson_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression\n",
        "\n",
        "A popular model used in classification problems is given by the logistic regression, it is the sister of linear regression, but for classification purposes (yes or no type of answers).\n",
        "\n",
        "In this lesson, we will learn how it works under the hood and make explicit the mathematical machinery behind it. To clarify the abstract concepts, we will use the UCI Machine Learning Repository's Automobile [dataset](https://archive.ics.uci.edu/ml/datasets/Automobile) and test it in practice.\n",
        "\n",
        "Let's start by loading the dataset:"
      ],
      "metadata": {
        "id": "IoAGLy6TfDCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ftQZDba9hfUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f674cf-a636-463e-d826-d47d399c53cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/automobiles.csv')"
      ],
      "metadata": {
        "id": "JxjN4q0uhuLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto.head()"
      ],
      "metadata": {
        "id": "mc9aLO_yibjP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "300a4666-5c27-45b0-9855-16a273c6b17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   symboling  normalized_losses  make fuel_type aspiration num_of_doors  \\\n",
              "0          2                164  audi       gas        std         four   \n",
              "1          2                164  audi       gas        std         four   \n",
              "2          1                158  audi       gas        std         four   \n",
              "3          1                158  audi       gas      turbo         four   \n",
              "4          2                192   bmw       gas        std          two   \n",
              "\n",
              "  body_style drive_wheels engine_location  wheel_base  ...  engine_size  \\\n",
              "0      sedan          fwd           front        99.8  ...          109   \n",
              "1      sedan          4wd           front        99.4  ...          136   \n",
              "2      sedan          fwd           front       105.8  ...          136   \n",
              "3      sedan          fwd           front       105.8  ...          131   \n",
              "4      sedan          rwd           front       101.2  ...          108   \n",
              "\n",
              "   fuel_system  bore  stroke compression_ratio horsepower  peak_rpm city_mpg  \\\n",
              "0         mpfi  3.19     3.4              10.0        102      5500       24   \n",
              "1         mpfi  3.19     3.4               8.0        115      5500       18   \n",
              "2         mpfi  3.19     3.4               8.5        110      5500       19   \n",
              "3         mpfi  3.13     3.4               8.3        140      5500       17   \n",
              "4         mpfi  3.50     2.8               8.8        101      5800       23   \n",
              "\n",
              "   highway_mpg  price  \n",
              "0           30  13950  \n",
              "1           22  17450  \n",
              "2           25  17710  \n",
              "3           20  23875  \n",
              "4           29  16430  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-424fca42-82c8-4426-a915-6a48b299990b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>normalized_losses</th>\n",
              "      <th>make</th>\n",
              "      <th>fuel_type</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>num_of_doors</th>\n",
              "      <th>body_style</th>\n",
              "      <th>drive_wheels</th>\n",
              "      <th>engine_location</th>\n",
              "      <th>wheel_base</th>\n",
              "      <th>...</th>\n",
              "      <th>engine_size</th>\n",
              "      <th>fuel_system</th>\n",
              "      <th>bore</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peak_rpm</th>\n",
              "      <th>city_mpg</th>\n",
              "      <th>highway_mpg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>...</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>105.8</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>17710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>105.8</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.3</td>\n",
              "      <td>140</td>\n",
              "      <td>5500</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>23875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>192</td>\n",
              "      <td>bmw</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>101.2</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.8</td>\n",
              "      <td>8.8</td>\n",
              "      <td>101</td>\n",
              "      <td>5800</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>16430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-424fca42-82c8-4426-a915-6a48b299990b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-424fca42-82c8-4426-a915-6a48b299990b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-424fca42-82c8-4426-a915-6a48b299990b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data contain 26 features. We will create a binary target variable called 'high price' which will show 1 for cars above $15,000 and 0 otherwise."
      ],
      "metadata": {
        "id": "DGxZCqfLirwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create binary target variable\n",
        "auto['high_price'] = auto['high_price'].apply(lambda x:  1 if x > 15000 else 0 )\n",
        "auto.drop('price', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "aM4pi19lltn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto['high_price'].value_counts()"
      ],
      "metadata": {
        "id": "S_lLaLdrpvAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1035899-9c98-408f-a706-a2e72ad903c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    119\n",
              "1     40\n",
              "Name: high_price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto.info()"
      ],
      "metadata": {
        "id": "V_MW6Cdqi7Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7609a8-72fa-4441-fb97-0a8865706768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159 entries, 0 to 158\n",
            "Data columns (total 26 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   symboling          159 non-null    int64  \n",
            " 1   normalized_losses  159 non-null    int64  \n",
            " 2   make               159 non-null    object \n",
            " 3   fuel_type          159 non-null    object \n",
            " 4   aspiration         159 non-null    object \n",
            " 5   num_of_doors       159 non-null    object \n",
            " 6   body_style         159 non-null    object \n",
            " 7   drive_wheels       159 non-null    object \n",
            " 8   engine_location    159 non-null    object \n",
            " 9   wheel_base         159 non-null    float64\n",
            " 10  length             159 non-null    float64\n",
            " 11  width              159 non-null    float64\n",
            " 12  height             159 non-null    float64\n",
            " 13  curb_weight        159 non-null    int64  \n",
            " 14  engine_type        159 non-null    object \n",
            " 15  num_of_cylinders   159 non-null    object \n",
            " 16  engine_size        159 non-null    int64  \n",
            " 17  fuel_system        159 non-null    object \n",
            " 18  bore               159 non-null    float64\n",
            " 19  stroke             159 non-null    float64\n",
            " 20  compression_ratio  159 non-null    float64\n",
            " 21  horsepower         159 non-null    int64  \n",
            " 22  peak_rpm           159 non-null    int64  \n",
            " 23  city_mpg           159 non-null    int64  \n",
            " 24  highway_mpg        159 non-null    int64  \n",
            " 25  high_price         159 non-null    int64  \n",
            "dtypes: float64(7), int64(9), object(10)\n",
            "memory usage: 32.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values but many of the features are non-numeric and would need to be transformed for machine learning. Since we will focus on the mathematical concepts rather than model building in this lesson, we will leave it as it is."
      ],
      "metadata": {
        "id": "IydqYISJi9AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check statistics\n",
        "auto.describe()"
      ],
      "metadata": {
        "id": "1Sfa6VwrjNW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9b001dfe-f49a-4b12-b2c5-465f187109a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        symboling  normalized_losses  wheel_base      length       width  \\\n",
              "count  159.000000         159.000000  159.000000  159.000000  159.000000   \n",
              "mean     0.735849         121.132075   98.264151  172.413836   65.607547   \n",
              "std      1.193086          35.651285    5.167416   11.523177    1.947883   \n",
              "min     -2.000000          65.000000   86.600000  141.100000   60.300000   \n",
              "25%      0.000000          94.000000   94.500000  165.650000   64.000000   \n",
              "50%      1.000000         113.000000   96.900000  172.400000   65.400000   \n",
              "75%      2.000000         148.000000  100.800000  177.800000   66.500000   \n",
              "max      3.000000         256.000000  115.600000  202.600000   71.700000   \n",
              "\n",
              "           height  curb_weight  engine_size        bore      stroke  \\\n",
              "count  159.000000   159.000000   159.000000  159.000000  159.000000   \n",
              "mean    53.899371  2461.138365   119.226415    3.300126    3.236352   \n",
              "std      2.268761   481.941321    30.460791    0.267336    0.294888   \n",
              "min     49.400000  1488.000000    61.000000    2.540000    2.070000   \n",
              "25%     52.250000  2065.500000    97.000000    3.050000    3.105000   \n",
              "50%     54.100000  2340.000000   110.000000    3.270000    3.270000   \n",
              "75%     55.500000  2809.500000   135.000000    3.560000    3.410000   \n",
              "max     59.800000  4066.000000   258.000000    3.940000    4.170000   \n",
              "\n",
              "       compression_ratio  horsepower     peak_rpm    city_mpg  highway_mpg  \\\n",
              "count         159.000000  159.000000   159.000000  159.000000   159.000000   \n",
              "mean           10.161132   95.836478  5113.836478   26.522013    32.081761   \n",
              "std             3.889475   30.718583   465.754864    6.097142     6.459189   \n",
              "min             7.000000   48.000000  4150.000000   15.000000    18.000000   \n",
              "25%             8.700000   69.000000  4800.000000   23.000000    28.000000   \n",
              "50%             9.000000   88.000000  5200.000000   26.000000    32.000000   \n",
              "75%             9.400000  114.000000  5500.000000   31.000000    37.000000   \n",
              "max            23.000000  200.000000  6600.000000   49.000000    54.000000   \n",
              "\n",
              "       high_price  \n",
              "count  159.000000  \n",
              "mean     0.251572  \n",
              "std      0.435288  \n",
              "min      0.000000  \n",
              "25%      0.000000  \n",
              "50%      0.000000  \n",
              "75%      0.500000  \n",
              "max      1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9cd49cc-4fbd-44a4-9a73-ebe46cf49560\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>normalized_losses</th>\n",
              "      <th>wheel_base</th>\n",
              "      <th>length</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>curb_weight</th>\n",
              "      <th>engine_size</th>\n",
              "      <th>bore</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peak_rpm</th>\n",
              "      <th>city_mpg</th>\n",
              "      <th>highway_mpg</th>\n",
              "      <th>high_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.735849</td>\n",
              "      <td>121.132075</td>\n",
              "      <td>98.264151</td>\n",
              "      <td>172.413836</td>\n",
              "      <td>65.607547</td>\n",
              "      <td>53.899371</td>\n",
              "      <td>2461.138365</td>\n",
              "      <td>119.226415</td>\n",
              "      <td>3.300126</td>\n",
              "      <td>3.236352</td>\n",
              "      <td>10.161132</td>\n",
              "      <td>95.836478</td>\n",
              "      <td>5113.836478</td>\n",
              "      <td>26.522013</td>\n",
              "      <td>32.081761</td>\n",
              "      <td>0.251572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.193086</td>\n",
              "      <td>35.651285</td>\n",
              "      <td>5.167416</td>\n",
              "      <td>11.523177</td>\n",
              "      <td>1.947883</td>\n",
              "      <td>2.268761</td>\n",
              "      <td>481.941321</td>\n",
              "      <td>30.460791</td>\n",
              "      <td>0.267336</td>\n",
              "      <td>0.294888</td>\n",
              "      <td>3.889475</td>\n",
              "      <td>30.718583</td>\n",
              "      <td>465.754864</td>\n",
              "      <td>6.097142</td>\n",
              "      <td>6.459189</td>\n",
              "      <td>0.435288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>86.600000</td>\n",
              "      <td>141.100000</td>\n",
              "      <td>60.300000</td>\n",
              "      <td>49.400000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>2.540000</td>\n",
              "      <td>2.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>4150.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>94.500000</td>\n",
              "      <td>165.650000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>52.250000</td>\n",
              "      <td>2065.500000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>3.050000</td>\n",
              "      <td>3.105000</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>4800.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>96.900000</td>\n",
              "      <td>172.400000</td>\n",
              "      <td>65.400000</td>\n",
              "      <td>54.100000</td>\n",
              "      <td>2340.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>3.270000</td>\n",
              "      <td>3.270000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>5200.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>100.800000</td>\n",
              "      <td>177.800000</td>\n",
              "      <td>66.500000</td>\n",
              "      <td>55.500000</td>\n",
              "      <td>2809.500000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>3.560000</td>\n",
              "      <td>3.410000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>5500.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>115.600000</td>\n",
              "      <td>202.600000</td>\n",
              "      <td>71.700000</td>\n",
              "      <td>59.800000</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>258.000000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>4.170000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9cd49cc-4fbd-44a4-9a73-ebe46cf49560')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9cd49cc-4fbd-44a4-9a73-ebe46cf49560 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9cd49cc-4fbd-44a4-9a73-ebe46cf49560');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data seems clean enough for our purposes in this lesson. \n",
        "\n",
        "## Building a classifier"
      ],
      "metadata": {
        "id": "ShDhyZJnjkx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target\n",
        "X = auto.drop('high_price', axis = 1)\n",
        "y = auto['high_price']"
      ],
      "metadata": {
        "id": "gMyKLbmKkJtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 731, stratify = y)"
      ],
      "metadata": {
        "id": "STsKzeBBnrpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "HzfAZwskn-6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffbaf6c-134a-4a9a-d62b-1ccda4164ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    95\n",
              "1    32\n",
              "Name: high_price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "KoV1d1PxpPfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ce8abf-d8f7-47c5-981c-43fa5f37e238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    24\n",
              "1     8\n",
              "Name: high_price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By turning on the stratify on the target variable of train_test_split, we keep the same proportions on the train and test sets. That helps to reduce bias when building a model by keeping the samples (train and test) as good representatives of the population ( train + test in this case).\n",
        "\n",
        "## Understanding the logistic regression\n",
        "\n",
        "The logistic regression is a model build by the following mathematical equation:\n",
        "$$\n",
        "EY = h(Z)\n",
        "$$\n",
        "where,\n",
        "$$\n",
        "Z = \\alpha + \\beta X.\n",
        "$$\n",
        "We need a function $h$ to connect the independent variable $X$ to the predictors $EY$ (predictors are the predictions for the real outcomes $y$).This is a way to map a classification problem, which is binary, into a linear regression kind of problem, which deals with real numbers (keep reading to see how it is done).\n",
        "\n",
        "To illustrate this point, let's build a visualization. Let's check how the horsepower of an engine is related to the target variable high_price:"
      ],
      "metadata": {
        "id": "WjBGvieOpbSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data = auto, x = 'horsepower', y = 'high_price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8hRh766YrNk5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e115ba26-e2b8-409e-ef75-00f9a24c0223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no clear linear relation here, but the intuition to what we see in the graph above is similar to a linear relationship between two variables, i.e., cars with more powerful engines are *more likely* to be more expensive.\n",
        "\n",
        "The simplicity of a linear regression model relies on its **assumption** that there is a linear relationship between the features and the target variable. The predictions for this model are made by fitting the line that minimize the distance between all data points of a sample to this hypothetical line. Assuming a linear relationship for the data above would be naive, since there is no evident linear relationship between both variables (despite the intuition we presented above).\n",
        "\n",
        "The logistic regression model follows a similar idea to the linear regression model, but it assumes a more complicated function instead. That's the function $h$, called **logistic** or sigmoid function. Its definition is given by:\n",
        "$$\n",
        "h(X) = \\frac{1}{1 + e^{-(\\alpha + \\beta X)}}.\n",
        "$$\n",
        "\n",
        "Let's visualize the sigmoid curve on the plot above, by choosing some random values for the parameters $\\alpha$ and $\\beta$:\n"
      ],
      "metadata": {
        "id": "lm3cSZwDuHF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining variables to visualize how the logistic function acts on the data\n",
        "Z = -7 + 0.05*auto['horsepower']\n",
        "hZ = 1/(1+np.exp(-Z))\n",
        "# Save EY in a column for the horsepower\n",
        "auto['EY_horsepower'] =  1/(1+np.exp(-(-7 + 0.05*auto['horsepower']))) "
      ],
      "metadata": {
        "id": "7cWZyMe5voc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data = auto, x = Z, y = hZ)\n",
        "plt.ylabel('EY')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z39o5QezyTKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f9244a4f-7583-4395-9015-ecdeedbc5c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, given some feature of the dataset, the logistic function returns a value $EY$ between 0 and 1. The target variable values $y$ are either 0 or 1, but not something in between. The interpretation given to the result of the logistic transformation is the probability of obtaining a positive value for the target."
      ],
      "metadata": {
        "id": "rrrz1loPOVWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probability, odds and log-odds\n",
        "\n",
        "So we know how to calculate the predictors $EY$ using the non-trivial logistic function once we have the independent variables $X$. However, in order to interpret the logistic regression model more clearly it is useful to find the inverse problem, *i.e.*, how the predictors influence the variables $X$. In other words, we want to find a function:\n",
        "$$\n",
        "X = f(EY).\n",
        "$$\n",
        "\n",
        "Let's do the maths starting with the logistic regression model:\n",
        "$$ \n",
        "EY = h(Z),\\\\\n",
        "Z = \\alpha + \\beta*X\n",
        "$$\n",
        "by taking the inverse of the $h$ function we obtain:\n",
        "$$\n",
        "h^{-1}(EY) = Z.\n",
        "$$\n",
        "Since we know that,\n",
        "$$\n",
        "EY = h(Z) = \\frac{1}{1 + e^{-Z}}\\\\\n",
        "1 + e^{-Z} = \\frac{1}{EY}\\\\\n",
        "Z = log(\\frac{EY}{1-EY}).\n",
        "$$\n",
        "Thus,\n",
        "$$\n",
        "log(\\frac{EY}{1-EY}) = \\alpha + \\beta*X.\n",
        "$$\n",
        "\n",
        "Compare it to the linear regression model\n",
        "$$\n",
        "Y = \\alpha + \\beta*X.\n",
        "$$\n",
        "\n",
        "In the linear regression model the coefficients $\\alpha$ and $\\beta$ are chosen to minimize the distance from the line to all dataset points, that is not the same in the logistic regression model.\n",
        "\n",
        "The difference is that the linear relation is not between the features and the outcomes, but an explicitly function of the probability of obtaining a positive result for the target. This function is very important in machine learning and is named **logit function**. It tells how the predictors $EY$ influence the features (just isolate $X$ on the last equation and you have $X$ in function of $EY$). Because it 'links' a function of the predictor with a linear model, it is commonly said that the logit function is the link function for the logistic regression model.\n",
        "\n",
        "As we saw above, $EY$ returns a value between 0 and 1. It is interpreted as the probability of obtaining the value 1 given a feature of of a dataset. In our example, it gives the probability of a value of a car to be above $15,000.\n",
        "\n",
        "Since it is easier to work with linear models, it is tempting **not** to use the $EY$ values and the sigmoid function but the linear model that is linked to the logit function. The argument of the logit function also has a well known meaning, it is called the odds. In mathematical terms, the odds are defined by:\n",
        "$$\n",
        "odds = \\frac{EY}{1-EY},\n",
        "$$\n",
        "It measures the likelyhood of obtaining a particular outcome. Instead of varying in the interval [0,1], it varies from [0, $\\infty$]. \n",
        "\n",
        "Another name for the logit function is then log-odds. It is a function varying from [-$\\infty$, $\\infty$] and since it is connect to the linear model, we know that the straight line on the linear version of the logistic regression also varies from -$\\infty$ to $\\infty$.\n",
        "\n",
        "Let's visualize that afirmation in the auto dataset:\n",
        "\n"
      ],
      "metadata": {
        "id": "uEMhJ1luyigd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a log-odds column\n",
        "auto['log-odds_horsepower'] = np.log(auto['EY_horsepower']/(1-auto['EY_horsepower']))\n",
        "\n",
        "# Plot log-odds versus horsepower (what kind of relation would you expect to see?)\n",
        "sns.scatterplot(data = auto, x = 'horsepower', y = 'log-odds_horsepower').set(title = 'Linearization of the sigmoid curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bP8FL2vmPXAh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "59f86d18-3b09-428d-d9af-4e1b564228ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the relationship between the horsepower and the log-odds of the this feature is linear.\n",
        "\n",
        "The question now is, what is the meaning of the coefficients of the linear relationship and how do we calculate the best set of parameters?"
      ],
      "metadata": {
        "id": "l3rnz2ZiwrUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Logistic cost function\n",
        "\n",
        "We  will focus on the second question in this lesson: How do we choose the best coefficients for a logistic regression model?\n",
        "\n",
        "First, we must say there is no closed form for the solution of this problem. This means there is no mathematical formula that we can always use to calculate the coefficients.\n",
        "\n",
        "For the linear regression, one can minimize the sum of the squared errors which leads to a closed form mathematical equation for the coefficients:\n",
        "$$\n",
        "\\beta_{linreg} = (X^TX)^{-1}X^TY \n",
        "$$\n",
        "There is no such expression for the logistic regression.\n",
        "\n",
        "The way around it is to use a log-loss cost function. For a binary classification problem it is defined by:\n",
        "$$\n",
        "L_{logreg}(\\alpha,\\beta) = \n",
        "\\begin{cases}\n",
        "  -\\log(h(\\alpha + \\beta*X)), \\hspace{1cm} \\text{if} \\hspace{1cm}  y= 1, \\\\\n",
        " -\\log(1 - h(\\alpha + \\beta*X)), \\hspace{1cm} \\text{if} \\hspace{1cm}  y= 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "Since $EY = h(X)$ we know that the argument of the logarithm functions above varies from [0,1]. This implies the log of the argument varies from $[\\infty, 0]$ for $y = 1$, *i.e.*, the loss tends to infinity when the probability of predicting 1 is low for a car that is known to have a high price  (in other words, loss goes to infinity when probability of predicting 1 goes to 0 when y = 1). That is just a way to let us know the model is doing badly. On the contrary, the loss function goes to zero when the probability of predicting 1 is high for a car that is known to have a high. \n",
        "\n",
        "Same idea when y = 0. However, the values vary from $[0,\\infty]$, i.e., the loss tends to zero when the probability of predicting 1 is low for a car that is known to have low price. The model is doing well in this case. On the other side, the loss tend to infinity when the probability of predicting 1 is high for a car that is known to have a low price. The model is doing badly in this case.\n",
        "\n",
        "\n",
        "Let's visualize this functions using the EY_horsepower feature we created above:"
      ],
      "metadata": {
        "id": "ZXuud_llfT4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating variable for the log-loss cost functions\n",
        "auto['L'] = 0\n",
        "auto.loc[auto['high_price'] == 0,  'L'] = -np.log(1 - auto['EY_horsepower'])\n",
        "auto.loc[auto['high_price'] == 1, 'L'] = -np.log(auto['EY_horsepower'])"
      ],
      "metadata": {
        "id": "-YwiWL7R3xI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing log-loss cost functions for a binary target \n",
        "sns.scatterplot(data = auto, x = 'EY_horsepower', y = 'L')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "gjzvL6Ul6JRP",
        "outputId": "a8c895a0-20c9-4f02-d326-a7f19d1f5ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAe+klEQVR4nO3dfXRU933n8fd39MAICQ0gCUmAsaAmdS0JCJUpOYkbNw9bShogjhfHbdI49oYmTcpJafakSR3sYLfddLuk8cYnKU3cxG6TmCQOlhuv026cjZ2usS07PEhmE2OMzYMkZIE1QjB6YH77x1wNQhqBZHTnzuh+XufoeHTnavjOWJrP/B7u72fOOUREJLwiQRcgIiLBUhCIiIScgkBEJOQUBCIiIacgEBEJucKgC5isyspKV1dXF3QZIiJ55bnnnnvNOVeV6b68C4K6ujpaWlqCLkNEJK+Y2Svj3aeuIRGRkFMQiIiEnIJARCTkFAQiIiGnIBARCbm8mzWUDwYGzrHveA8d8QS15VEa58coLi4IuiwRkYwUBFNsYOAcu/YdZ+vDrSQGk0SLImxb38CGZfMVBiKSk9Q1NMX2He9JhwBAYjDJ1odb2Xe8J+DKREQyUxBMsY54Ih0CwxKDSTrjiYAqEhG5OAXBFKstjxItuvBljRZFqC6PBlSRiMjFKQimWOP8GNvWN6TDYHiMYNn8WMCViYhkpsHiKVZcXMCGZfNZUllKZzxBdXmUZZo1JCI5TEHgg+LiAprq5gZdhojIhCgIfJZMOg5396VbB3UVpUQiFnRZIiJpCgIfJZOOx9o62LJzT/qagu0bV7CmvkZhICI5Q4PFPjrc3ZcOAUhNI92ycw+Hu/sCrkxE5DwFgY86x7mm4ESvrikQkdyhIPBR9TjXFMybpWsKRCR3KAh8VFdRyvaNKy64pmD7xhXUVZQGXJmIyHkaLPZRJGKsqa/h6s3XcaI3wbxZmjUkIrlHQeCzSMRYUlXGkqqyoEsREclIXUMiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyuIwjI0FCStvYe2nsS1MZKqK8tp7BQuSwi2acgCMDQUJJde49x+67W9PLUd29oYMPyBQoDEck6vesEoK29Jx0CkFqR9PZdrbS19wRcmYiEkYIgAO09mZen7ujR8tQikn0KggDUxkoyLk9dE9Py1CKSfQqCANTXlnP3hoYLlqe+e0MD9bWxgCsTkTDSYHEACgsjbFi+gKXzyujoSVATi1JfG9NAsYgEwrcgMLMrgPuBasABO5xzXx51jgFfBtYCZ4BbnHPP+1VTLiksjLD8ijksvyLoSkQk7PxsEQwBf+6ce97MZgHPmdm/O+deGHHO7wFLva/fAr7q/VdERLLEt74I51z78Kd751wvcABYMOq09cD9LmU3MNvMav2qSURExspKp7SZ1QFvBp4eddcC4MiI748yNiwws01m1mJmLV1dXX6VKSISSr4HgZmVAT8APuWci7+Rx3DO7XDONTnnmqqqqqa2QBGRkPM1CMysiFQI/Itz7qEMpxwDRg6XLvSOiYhIlvgWBN6MoG8AB5xz28c5rRn4I0tZDfQ459r9qklERMbyc9bQW4EPAfvNbI937HPAIgDn3NeAR0lNHT1IavroR3ysR0REMvAtCJxzPwfsEuc44BN+1SAiIpemS1lFREJOQSAiEnJaayjHJZOOw919dMYTVJdHqasoJRK5aI+biMikKAhyWDLpeKytgy0796R3Mtu+cQVr6msUBiIyZdQ1lMMOd/elQwBSm9ds2bmHw919AVcmItOJgiCHdcYz72R2olc7mYnI1FEQ5LDq8mjGnczmzdJOZiIydRQEOayuopTtG1dcsJPZ9o0rqKsoDbgyEZlONFicwyIRY019DVdvvo4TvQnmzdKsIRGZegqCHBeJGEuqylhSVRZ0KSIyTalrSEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScpo+Og0MDJxj3/EeOuIJasujNM6PUVxcEHRZIpInFAR5bmDgHLv2HWfrw63pFUq3rW9gw7L5CgMRmRB1DeW5fcd70iEAqUXptj7cyr7jPQFXJiL5QkGQ5zrGWaG0M64VSkVkYhQEea52nBVKq8u1QqmITIyCIM81zo+xbX3DBSuUblvfwLL5sYArE5F8ocHiPFdcXMCGZfNZUlma3td4mWYNicgkKAimgeLiAprq5gZdhojkKXUNiYiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTtNHQySRGGJ/ew8d8X5qymfQWBsjGtWvgEjY6V0gJBKJIZr3t7O1ecQqpesaWNdYqzAQCTl1DYXE/vaedAiAt0ppcyv727VKqUjY+RYEZnafmZ0ws9Zx7r/ezHrMbI/3tdWvWgQ64v0ZVyntiPdzqOs0yaQLqDIRCZqfLYJvAmsucc6TzrkV3tc2H2sJvZryGRlXKa0oK2btPU/yWFuHwkAkpHwLAufcE8BJvx5fJqexNsa2daNWKV1Xz/effZXEYJItO/dwuLsv4CpFJAhBjxK+xcz2AseBTzvn2jKdZGabgE0AixYtymJ500c0Wsi6xloWV86kI95PRVkx33/2VR7a005tLMoNKxfyq85eAOoqSolELOCKRSRbggyC54ErnXOnzWwtsAtYmulE59wOYAdAU1OT+i/eoGi0kGsXV3Co6zRr73mSxGCS2liUD62+knsefzE9m2j7xhWsqa9RGIiERGCzhpxzcefcae/2o0CRmVUGVU+Y1FWUsn3jCqJFEW5YuTAdAoC6iURCKLAgMLMaMzPv9iqvlu6g6gmTSMRYU1/Do5uvo3FBecbZRCd6teexSFj41jVkZt8BrgcqzewocAdQBOCc+xpwI/BxMxsCzgIfcM6p2ydLIhFjSVUZkBo4HhkG0aII82Zpz2ORsPAtCJxzN1/i/q8AX/Hr35eJGe4m2rJzzwVjBHUVpUGXJiJZEvSsIQnYcDfR1Zuv40Rvgnmzopo1JBIyCgJJdxMNdxWJSLhorSERkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5zRqSSUsmHYe7++iMJ6gu13RTkXynIJBJSSYdj7V1jLkATYvUieQvdQ3JpBzu7kuHAGiROpHpQEEgk9IZT2RcpO6F9jh7j7zO0FBynJ8UkVylIJBJqS6PZtzy8kB7LzfteIpde48pDETyjIJAJmXkXgaQCoHN71jKQ88fJTGY5PZdrbS19wRcpYhMhgaLZVJGLlL3QnucA+29PLD7Fdp7UvsXJAaTdPQkWH5FwIWKyIQpCGTShhep600M8env7R2zl0FNTHsZiOQTdQ3JG1ZfW87dGxou6Ca6e0MD9bWxgCsTkclQi0DesMLCCBuWL2DpvDI6ehLUxKLU18YoLEwFQyIxxP72Hjri/dSUz6CxNkY0ql85kVyjv0q5LIWFEZZfMWfMmEAiMUTz/na2NremLzzbtq6BdY21CgORHKOuIfHF/vaedAhAahB5a3Mr+zWjSCTnKAjEFx3x/owXnnXG+wOqSETGoyAQX9SUz8h44Vl1+YyAKhKR8bzhIDCzT01lITK9NNbG2LbuwhlF29Y10KgZRSI553JG7bYAfz9Vhcj0Eo0Wsq6xlsWVM+mM91OtWUMiOety/iq15rBcVDRayLWLK4IuQ0Qu4XLGCNyUVSEiIoG5aIvAzHrJ/IZvQIkvFYmISFZdNAicc7OyVYiIiARD00dFREJOQSAiEnIKAhGRkNOkbhHJaGDgHPuO99ART1BbHqVxfozi4oKgyxIfKAhEZIyBgXPs2necrQ+PWD12fQMbls1XGExD6hoSkTH2He9JhwB4q8c+3Mq+41o9djryLQjM7D4zO2FmrePcb2Z2j5kdNLN9ZrbSr1pEZHI64olxVo9NBFSR+MnPFsE3gTUXuf/3gKXe1ybgqz7WIiKTUFseHWf1WO1HPR35FgTOuSeAkxc5ZT1wv0vZDcw2s1q/6hGRiWucH2Pb+lGrx65vYNl8rR47HQU5WLwAODLi+6PesfbRJ5rZJlKtBhYtWpSV4kTCrLi4gA3L5rOkspTOeILq8ijLNGto2sqLWUPOuR3ADoCmpiYtdieSBcXFBTTVzQ26DMmCIGcNHQNGbnm+0DsmIiJZFGQQNAN/5M0eWg30OOfGdAuJiIi/fOsaMrPvANcDlWZ2FLgDKAJwzn0NeBRYCxwEzgAf8asWEREZn29B4Jy7+RL3O+ATfv37IiIyMbqyWEQk5BQEIiIhpyAQEQk5BYGISMjlxQVlIn5JJh2Hu/vSV8/WVZQSiVjQZYlklYJAQiuZdDzW1sGWnXvSa+5v37iCNfU1CgMJFXUNSWgd7u5LhwCkllnesnMPh7v7Aq5sfMmk41DXaZ566TUOdZ0mmdSKK3L51CKQ0OocZ839E70JllSVBVTV+NSCEb+oRSChVT3OmvvzZuXmmvv52IKR/KAgkNCqqyhl+8YVF6y5v33jCuoqSgOuLLOLtWBELoe6hiS0IhFjTX0NV2++jhO9CebNyu1ZQ8MtmJFhkMstGMkfahFIqEUixpKqMlYvqWRJVVnOhgDkXwtG8odaBCJ5It9aMJI/FAQieWS4BZOLs5okf6lrSEQk5BQEIiIhpyAQEQk5jRGI+EiL2kk+UBCI+ERLQki+UNeQiE+0JITkCwWBiE+0JITkC3UNifhkIktCaAxBcoFaBCI+udSSEMNjCGvveZKb//Fp1t7zJI+1dWiPAck6tQhEfHKpJSEyjSF88bEDLJgd5czAObUQJGsUBCI+utiSEKPHEGpjUW5qWsRNO3ZrlpFklbqGRAIyemOcG1Yu5J7HX9QsI8k6BYFIQEaPIRRE0CwjCYS6hkQCMnoMoaSokB1PHNLGM5J1ahGIBGjkxjiNC2LaeEYCoRaBSI7QxjMSFAWBSA7RxjMSBHUNiYiEnIJARCTkfA0CM1tjZr80s4Nm9hcZ7r/FzLrMbI/39V/8rEdERMbybYzAzAqAe4F3A0eBZ82s2Tn3wqhTH3TOfdKvOkRE5OL8bBGsAg465w455waA7wLrffz3RETkDfAzCBYAR0Z8f9Q7Ntr7zWyfmX3fzK7wsR4REckg6MHiR4A659wy4N+Bb2U6ycw2mVmLmbV0dXVltUARkenOzyA4Boz8hL/QO5bmnOt2zvV7334d+M1MD+Sc2+Gca3LONVVVVflSrIhIWPkZBM8CS81ssZkVAx8AmkeeYGa1I75dBxzwsR4REcnAt1lDzrkhM/sk8GOgALjPOddmZtuAFudcM7DZzNYBQ8BJ4Ba/6hERkczMufzaFq+pqcm1tLQEXYaISF4xs+ecc02Z7gt6sFhERAKmRedE5LIlk47D3X10xhPaazkPKQhE5LIkk47H2jrYsnOP9lrOUwoCEbksh7v70iEAMGdmMf+vI060KEJdRalaB3lAQSAil6UznkiHQG0syodWX8k9j7+o1kEe0WCxiFyW6vJoenvNG1YuTIcAQGIwyZadezjc3RdkiXIJCgIRuSx1FaXpvZbNSIfAsMRgkhO9iYCqk4lQ15CIXJaRey13ne7n608euiAMokUR5s2KXvQxzp4dZH9HnM54P9XlM2isKaekpMjv0sWjIBCRyza81/Jw62D0DKK6itJxf/bs2UEeae1ga3Nr+me2rWvgvQ01CoMsURCIyJQZ2To40Ztg3qxLX1OwvyOeDgFIdSVtbW6lJjaDWEkx9bXlFBaqF9tPCgIRmVLDrYMlVWUTOr8z3p9xXOGZw6fY/VIXf/buX6c3MURtrESh4BMFgYgEqrp8BtGiyJhxhdklhbx/5SJu+1ZLusvo7g0NbFi+QGEwxfRqCqfPJnjm5W4e2XucZ17u5vRZzfCQ7GmsKWfbuob0FNRoUYTN71jKFXNL+cK/tl3QZXT7rlba2nuCLHdaUosgRIaGkrS199Dek0g3sxODAzza2jVmoG5tQxVlJRef6SEyFUpKinhvQw11lTM52TfAC+1xHtj9Cp9659KMXUYdPQmWa1PbKaUgCImhoSS79h7j9l2tFzSzl84ryzhQV1e5ilWLFQSSHSUlRaxaXMHQUJLT/UOcOjPAzBmFGbuMamL6vZxq6hqapoaGkuw9corHWtvZe+R1Wo/3pEMAzjez+wbOZfzU1Rnvz/SwIr4qLIywYfkCHty0mjkzC7hr/YVdRndvaKC+NhZwldOPWgTTzNBQkhe74uw/1svWh89/+v/bG5dlfMM/1TeQ8VNXdfmMbJcuAqTCYPkVc4DU7/Obqsvo6ElQE4tSXxvTQLEPFATTwHDffzwxQEfPACVFBekQgNQbfsQs4xv+/NlRtq1rGDNGcE3N+BcAiWTLcChoTMBfitY8N9z3f9OO3Zw6c47PP9xKX//QmE//O372EtsyNLMb589mbUMV99+6iv9585u5/9ZVGigWCRm1CPJcW/v5vv+zXgBkGmT71YnTNC6YxYObVo9pZpcVRjUwLBJiCoI8195zfi344QD4xyde4o7fr0/PwU7PEKoq95raARctIjlFQZDnamMl6U//IwPgO8+8wt/duByH44o5M2mYr0E2kcsxnfdlVhAELJEYYn97Dx3xfmrKZ9BYGyManfj/lvracu7e0MDtu1rZdyxO8fOv8o0PN3lrs2iWhchUmO77MisIAjA0lKTteA/t8QTFhRG+8Egbr3SfTc/YWddYO+EwGJ53vXSeptiJ+GX0vszDO69dvfm6CS+ul8sUBFmW6Qrfze9YygO7X6G9J8HW5lYWV87k2sUVE35MTbET8dfIfZmHDe+8piCQjEb2JVaWzaCvf4ijr5+ltjxKUaGNucL3nsdf5La3LeHenx7UVb0iOWh4X+bJ7ryWL9R/MMUGBs7x9MvdPHv4JK+dHuCzD+3lqUPd/NWPDvCH33ial7vOZPxkYV43o67qFck9I/dlBia081o+UYvgMgx/8m9//SxFhRFOnRlk9swifvj8q+x8rp1oUYQ7fr+eHzz/KjesXMi9Pz3IoddOZ/xk4RzpMYJGraUiklPeyM5r+URBMAnDM3ySJCmKFPBSVx+ff/jCvv4HW17lE9dfxdA5eGhPO1/41zb+9sbl/KqzF4CdLUe5a33DBT/3V+9rpGxGAQ/cumrSs4ZEJDsmu/NaPtE7zkWcPTvI/o44nfF+FlfO5MzAOTrj/VTNKuZAe5y7fnQgY1//1uY27rvlWh7a005iMEliYAjnUo956swAS+eV8eBHV3Os5yyVpTOojs3gijnT59OFiOQXBcEII9/431Q9k71Hetna3MpbFs9lTWMtdzSfv1L3v92QeTVPs9R/u0+nBnyjRRFqYyV86X+/mOr6Wd/ANTXlFBcXsJw5QTxNEckzfl/MFuogiJ9N0NWboOdMkt6BIRKD56gqK+ah547wseuvSq/IecvbFvPHDzx3waf/ly/R119RltqH9a71DVSUFXH7e36D6vIoy+bHKC4uCOopi0ieycbFbKEKgmTS8erJPgbPDXHqzDlmRY0T8SG6Tvdz5OQZdrYc5dSZAf7mfY28fnYg/SZ/qm9wzKf/TH39w2ME29Y1MKPA8eCm1emLu66ZPzuIpywieS4bF7OFIgiSScfR1/tof72f1073M7e0mKRLcqB9gM/9cP+YC7s++8P93H/rqvQn/rmlRWM+/Z86M8CCOVE2/fYSrqmdxdzSGbx+ZpC/u3G5BnxFZMpk42I2X68jMLM1ZvZLMztoZn+R4f4ZZvagd//TZlY31TUkk44nD55g90sn+fA/PcMnvv0LPvLNZ0kMunQIwPnB3htWLkzv3LVtXT3Rogj/9POX+YJ3G85P80w6x9uuquTtv1bFqsUV/Kf6Gq5dXKEQEJEpM3wx20hTfTGbb+9YZlYA3Au8GzgKPGtmzc65F0acdhtwyjl3lZl9APgicNNU1nG4u4/es+fY6g30QupNf+/R18cd7I0WRSgpLmD2zALuv3VVetbQ/beu4kS8n5qY+vpFJDuGL2YbPUYwlRez+fnRdRVw0Dl3CMDMvgusB0YGwXrgTu/294GvmJk5NzzZ8vJ1xhMZd+xKeoO6owd7IwZ/875G5pYW82tzSykpKZqqUkREJi0bF7P52TW0ADgy4vuj3rGM5zjnhoAeYMxqa2a2ycxazKylq6trUkVUl0cpjRaOaVo9svcYd2XYuvF3r5nHexpqaVgwWyEgIjlh+GK21UsqWVJVNuXXHOVFZ7ZzbgewA6CpqWlSrYW6ilKOnOrjzvfWc+cj568D+Njbr6KyrIh/vu23OHVmgFhJEW+qKWW29uoVkZDxMwiOASMXRl7oHct0zlEzKwRiQPdUFhGJGNddNY8jp/p44NZVnOhNzRoqm1HIr8+bpX5+EQk9P4PgWWCpmS0m9Yb/AeAPRp3TDHwYeAq4EXh8KscHhkUixpUVZVxZMf3WCBERuVy+BYFzbsjMPgn8GCgA7nPOtZnZNqDFOdcMfAN4wMwOAidJhYWIiGSRr2MEzrlHgUdHHds64nYC+M9+1iAiIhenjWlEREJOQSAiEnIKAhGRkDMfJun4ysy6gFcm8SOVwGs+lZMvwv4ahP35g14D0GtwpXOuKtMdeRcEk2VmLc65pqDrCFLYX4OwP3/QawB6DS5GXUMiIiGnIBARCbkwBMGOoAvIAWF/DcL+/EGvAeg1GNe0HyMQEZGLC0OLQERELkJBICISctMmCHJhf+QgTeD5bzGzF8xsn5n9xMyuDKJOP13qNRhx3vvNzJnZtJtKOJHXwMw2er8LbWb27WzX6KcJ/B0sMrOfmtkvvL+FtUHUmXOcc3n/RWp105eAJUAxsBe4ZtQ5fwJ8zbv9AeDBoOvO8vP/HWCmd/vj0+n5T/Q18M6bBTwB7Aaagq47gN+DpcAvgDne9/OCrjvLz38H8HHv9jXA4aDrzoWv6dIiSO+P7JwbAIb3Rx5pPfAt7/b3gXea2dTu9xacSz5/59xPnXNnvG93k9ooaDqZyO8AwF3AF4FENovLkom8Bh8F7nXOnQJwzp3Ico1+msjzd0C5dzsGHM9ifTlrugTBlO2PnKcm8vxHug34X75WlH2XfA3MbCVwhXPuR9ksLIsm8nvwJuBNZvYfZrbbzNZkrTr/TeT53wl80MyOkloi/0+zU1puy4s9i2XqmNkHgSbg7UHXkk1mFgG2A7cEXErQCkl1D11PqlX4hJk1OudeD7Sq7LkZ+KZz7n+Y2VtIbYzV4JxLBl1YkKZLi2Ay+yPj1/7IAZrI88fM3gX8JbDOOdefpdqy5VKvwSygAfg/ZnYYWA00T7MB44n8HhwFmp1zg865l4FfkQqG6WAiz/82YCeAc+4pIEpqMbpQmy5BkN4f2cyKSQ0GN486Z3h/ZPBxf+SAXPL5m9mbgX8gFQLTqV942EVfA+dcj3Ou0jlX55yrIzVOss451xJMub6YyN/BLlKtAcysklRX0aFsFumjiTz/V4F3ApjZb5AKgq6sVpmDpkUQeH3+w/sjHwB2Om9/ZDNb5532DaDC2x95CzDu9MJ8M8Hn/9+BMuB7ZrbHzEb/geS1Cb4G09oEX4MfA91m9gLwU+C/OuemRct4gs//z4GPmtle4DvALdPoA+EbpiUmRERCblq0CERE5I1TEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMhpiQnJW2Z2Dtg/4tB3SV1BXOic+4x3zpWk5suvzLSMgneVcZNz7jX/KxbJTQoCyWdnnXMrRh4wsxJgj5l90zl3APgy8Hk/1tIxs0LvIqacli91SnDUNSTTinPuLPBnwL3epiOznHP/cokf+1Mze97M9pvZ1QBmNtfMdnmbl+w2s2Xe8TvN7AEz+w9SC5bVm9kz3tXa+8xsqXfeB0cc/wczK/COnzazL3mbwvzEzKq84yu8f2efmf3QzOaY2Twze867f7m3mc4i7/uXzGymmVWZ2Q/M7Fnv662Z6pzq11mmFwWB5LMS7412+OsmAOfco8ApUvtP/MkEHuc159xK4KvAp71jXwB+4ZxbBnwOuH/E+dcA73LO3Qx8DPiy1zJpAo56a9jcBLzVO34O+EPvZ0uBFudcPfAz4A7v+P3AZ7x/bz9wh7cmVNTMyoHrgBbgOq+764S3v8SXgS85564F3g98fZw6RcalriHJZ2O6hka4Fyhxzv1yAo/zkPff54AbvNtvI/XGinPucTOr8N6QIbV651nv9lPAX5rZQuAh59yLZvZO4DeBZ729j0qA4YX+ksCD3u1/Bh4ysxgw2zn3M+/4t4Dvebf/L/BW4LeBvwbWAAY86d3/LuCaEXsslZtZWYY6RcalIJDpKul9TcTwktznmNjfRN/wDefct83saeA9wKNm9sek3qi/5Zz77AQe61KLfT1BqjVwJfAw8BnvZ4Y314kAq51zF+y45gVDHyIToK4hkcyexOvOMbPrSXUfxUefZGZLgEPOuXtIvVEvA34C3Ghm87xz5nrdOZD6m7vRu/0HwM+dcz3AKTO7zjv+IVLdRsN1fBB40ds85SSwFvi5d/+/MWKXLTMbr4UkMi61CCSflZjZnhHfP+acm6rlxe8E7jOzfcAZzu9lMdpG4ENmNgh0AH/tnDtpZrcD/+btjDYIfAJ4hdSn9FXe/SdIjSXgPf7XzGwmqf0BPgLgnDtsqY/3T3jn/RxYOLznMLCZ1MD4PlJ/z0+QGrcQmTAtQy2SRWZ22jlXdukzRbJHXUMiIiGnFoGEgpn9EFg86vBnnHM/DqIekVyiIBARCTl1DYmIhJyCQEQk5BQEIiIhpyAQEQm5/w+gwRtHzJOkcAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the two behaviors described above. A monotonically increasing function when $y = 0$ and a monotonically decreasing function when $y= 1$. The model is doing well for some of the data and badly for others. But how do we select the best model?\n",
        "\n",
        "## Gradient descent\n",
        "\n",
        "The rigorous mathematical calculation to find the optimal model is done by using gradient descent. Let's do a quick reminder of how it works.\n",
        "\n",
        "Suppose we want to find the minimum value $x = x_0$ for a function $f(x)$. The way linear gradient descent approach this problem is to start with a random choice for the initial value of the argument, $x=x_1$, and iterativaly update it through the following equation:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "x_n = x_{n-1} -  \\vec{\\lambda} \\cdot \\nabla  f(x_{n-1}).\n",
        "\\end{aligned}\n",
        "$$\n",
        "Here $x_n$ is the next value, $\\vec{\\lambda}$ is called the learning ratio and $\\nabla f(x_{n-1})$ is the gradient operator acting on the function at $x_{n-1}$.\n",
        "\n",
        "A few important comments:\n",
        "\n",
        "- Choosing the learning ratio wisely is important. If it is too small, the algorithm can reach the maximum amount of steps without finding the minimum. If it is too big, it can bypass the minimum and never get close to it.\n",
        "\n",
        "- The minus sign represents the fact that we want to find the minimum, so the  steps are towards a smaller value of $x$. To find the maximum of a function one would just change it to a plus sign.\n",
        "\n",
        "- The gradient finds a direction at the function's hypersurface where it grows more quickly. By subtracting its value (multiplied by the learning rate) we are making sure we are trying to approach the minimum more quickly.\n",
        "\n",
        "That's how linear GD generally works. A more detailed explanation can be found [here](https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21).\n",
        "\n",
        "## Grandient descent and the loss function\n",
        "\n",
        "The mean of the total log-loss function is given by:\n",
        "$$\n",
        "L^{avg}_{logreg}(\\alpha, \\beta) = \\frac{1}{n}\\bigg[\\sum_{i=1}^{n}\\big(- y_i*\\log(h(\\alpha + \\beta X_i)) - (1-y_i)*\\log(1 - h(\\alpha + \\beta X_i))\\big)\\bigg],\n",
        "$$\n",
        "where $i$ runs over every single observation. It is easy to see that it recovers the two different expressions given a value for $y$. This is the function we want to minimize in order to obtain the best values for the coefficients $\\alpha$ and $\\beta$.\n",
        "\n",
        "Comment:\n",
        "\n",
        "- Every single observation $(X_i,y_i)$ leads to a single loss **function** of the parameters $(\\alpha,\\beta)$. Minimizing one function would mean minimizing the loss for only one observation, however, we want the best **model** so we need to find a way to include all possible observations and find the values of the parameters $\\alpha$ and $\\beta$ that better represents all observations. That's why one chooses the average of the total loss here. \n",
        "\n",
        "Since \n",
        "$$\n",
        "\\nabla L(\\alpha, \\beta) = \\frac{\\partial L}{\\partial \\alpha} \\hat{\\alpha} +\\frac{\\partial L}{\\partial \\beta} \\hat{\\beta},\n",
        "$$\n",
        "we start by calculating the partial derivatives for the log-loss function:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial L}{\\partial \\alpha} &= \\frac{1}{n}\\bigg( \\sum_{i=1}^{n} \\bigg[y_i \\frac{1}{h(X_i)} + (1-y_i) \\frac{1}{(1 - h(X_i))}\\bigg]\\frac{\\partial h}{\\partial \\alpha} \\bigg)&\\\\\n",
        "&= \\frac{1}{n}\\bigg( \\sum_{i=1}^{n} \\bigg[\\frac{y_i(1 - h(X_i)) - (1- y_i)h(X_i) }{h(X_i)(1 - h(X_i))} \\bigg]\\frac{\\partial h}{\\partial \\alpha} \\bigg)&\\\\\n",
        " &= \\frac{1}{n}\\bigg( \\sum_{i=1}^{n} \\bigg[\\frac{h(X_i) - y_i  }{h(X_i)(1 - h(X_i))} \\bigg]\\frac{\\partial h}{\\partial \\alpha}\\bigg)&.\n",
        "\\end{aligned}\n",
        "$$\n",
        "It is not hard to show that\n",
        "$$\n",
        "\\frac{\\partial h}{\\partial \\alpha} = h^2 e^{-(\\alpha + \\beta X_i)}\n",
        "$$ \n",
        "and\n",
        "$$\n",
        "1 - h(X_i) = h(X_i) e^{-(\\alpha + \\beta X_i)}\n",
        "$$\n",
        "So, we finally have\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\alpha} = \\frac{1}{n}\\sum_{i=1}^{n}(h(\\alpha + \\beta X_i) - y_i).\n",
        "$$\n",
        "Similar calculations lead to:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\beta} = \\frac{1}{n}\\sum_{i=1}^{n}X_i (h(\\alpha + \\beta X_i) - y_i).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "yB4KpP24ECxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient descent implementation\n",
        "\n",
        "Let's apply this theory in the dataset we have in hands. First let's define the gradient descent function. It will take six parameters:\n",
        "\n",
        "- x: an array of values representing the independent variables (features) that will be used in the logistic regression,\n",
        "\n",
        "- outcomes: an array of values reprenting the outcomes associated to the x.\n",
        "\n",
        "- init: an array containing two values for our initial guess for the parameters we want to minimize,\n",
        "\n",
        "- iterations: the number of iterations the algorithm should take. We will set a default number of 1000.\n",
        "\n",
        "- learning_rate: a number representing the value of each step. The default will be 0.0001.\n",
        "\n",
        "- stopping_threshold: a number representing the maximum difference between the estimated parameters. The default is 1e-6. \n"
      ],
      "metadata": {
        "id": "kzuJHAphMa_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x, outcomes, init = np.array([0,0]), iterations = 1000, learning_rate = 0.0001, stopping_threshold = 1e-6):\n",
        "  \n",
        "  previous_cost = None\n",
        "  alpha0 = init[0]\n",
        "  beta0 = init[1]\n",
        "\n",
        "  # Perform iterations\n",
        "  for i in range(iterations):\n",
        "    # Calculate predictors EY = hz (here it is a vector containing the predictors for all values o X)\n",
        "    hz = 1/(1+np.exp(-(alpha0+beta0*x)))\n",
        "    # Calculate the cost function (it is also a vector)\n",
        "    cost = -outcomes*np.log(hz) - (1-outcomes)*np.log(1-hz)\n",
        "\n",
        "    if previous_cost and (abs(previous_cost) - cost <= stopping_threshold):\n",
        "      break\n",
        "    \n",
        "    alpha0 = alpha0 - learning_rate*np.mean(hz - outcomes)\n",
        "    beta0 = beta0 - learning_rate*np.mean(x*(hz - outcomes))\n",
        "    \n",
        "\n",
        "  return np.array([alpha0,beta0])"
      ],
      "metadata": {
        "id": "Yd2r6UbddyVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test GD algorithm in the auto dataset\n",
        "alpha, beta = gradient_descent(auto['horsepower'],auto['high_price'])"
      ],
      "metadata": {
        "id": "N03myD6JRDVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The best values for the coefficients for the logistic model, according to gradient_descent function, was: alpha = {alpha:.6f} and beta = {beta:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFVDFUY_SOKq",
        "outputId": "6d7968dd-2979-423c-a84a-b0d6f9c5ad7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best values for the coefficients for the logistic model, according to gradient_descent function, was: alpha = -0.010700 and beta = -0.006042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function above exemplifies how gradient descent could be performed in practice. However, there is room for improvement here. \n",
        "\n",
        "One can see that if the number of iterations is too low, the minimum value for the cost function could not be reached. If the learning rate is too small or too big, the minimum could also not be reached.\n",
        "\n",
        "One way to improve the function above is to print the number of iterations that took for the algorithm to end. If the maximum amount of iterations is reached, it is a good sign that the number of iterations and/or the number of learning rate should be slightly increased.\n",
        "\n",
        "One could also change the initial conditions, but we have no guidance to check how we should change it to make the algorithm better.\n",
        "\n",
        "Let's print how many iterations the algorithm takes for a given values of the initial conditions and experiment with it to prove this point:"
      ],
      "metadata": {
        "id": "FThhK_NcPfgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x, outcomes, init = np.array([0,0]), iterations = 1000, learning_rate = 0.0001, stopping_threshold = 1e-6):\n",
        "  \n",
        "  previous_cost = None\n",
        "  alpha0 = init[0]\n",
        "  beta0 = init[1]\n",
        "\n",
        "\n",
        "  # Perform iterations\n",
        "  for i in range(iterations):\n",
        "    # Calculate predictors EY = hz (here it is a vector containing the predictors for all values o X)\n",
        "    hz = 1/(1+np.exp(-(alpha0+beta0*x)))\n",
        "    # Calculate the cost function (it is also a vector)\n",
        "    cost = -outcomes*np.log(hz) - (1-outcomes)*np.log(1-hz)\n",
        "\n",
        "    number_iterations = i + 1 \n",
        "\n",
        "    if previous_cost and (abs(previous_cost) - cost <= stopping_threshold):\n",
        "      break\n",
        "    \n",
        "    alpha0 = alpha0 - learning_rate*np.mean(hz - outcomes)\n",
        "    beta0 = beta0 - learning_rate*np.mean(x*(hz - outcomes))\n",
        "    \n",
        "\n",
        "  return np.array([alpha0,beta0, int(number_iterations)])"
      ],
      "metadata": {
        "id": "cP90PSenWeTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First test with initial conditions $\\alpha = -7$ and $\\beta = 0.01$."
      ],
      "metadata": {
        "id": "vHbjQXtSX9I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test GD algorithm in the auto dataset alpha0 = -7, beta0 = 0.01\n",
        "alpha, beta, iterations = gradient_descent(auto['horsepower'],auto['high_price'], init = np.array([-7,0.01]))"
      ],
      "metadata": {
        "id": "Si6K5d44WeTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Initial conditions alpha = -7 and beta = 0.01 implies {iterations} iterations and best coefficients alpha = {alpha:.6f} and beta = {beta:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702d4e41-4d36-4dc6-e613-4e41a10fceb5",
        "id": "AxMBFTbNWeTM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial conditions alpha = -7 and beta = 0.01 implies 999.0 and best coefficients alpha = -7.000367 and beta = 0.057514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second test with initial conditions $\\alpha = 0$ and $\\beta = 0$."
      ],
      "metadata": {
        "id": "ddKlexWcYME_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test GD algorithm in the auto dataset alpha0 = 0, beta0 = 0\n",
        "alpha, beta, iterations = gradient_descent(auto['horsepower'],auto['high_price'], init = np.array([0,0]))"
      ],
      "metadata": {
        "id": "Df7DqWSdXFW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Initial conditions alpha = -7 and beta = 0.01 implies {iterations} iterations and best coefficients alpha = {alpha:.6f} and beta = {beta:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TIxflquX0oT",
        "outputId": "d3763227-1c4c-44d3-ce54-69ea39ba4a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial conditions alpha = -7 and beta = 0.01 implies 999.0 and best coefficients alpha = -0.010700 and beta = -0.006042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third test with initial conditions $\\alpha = -4$ and $\\beta = 3$."
      ],
      "metadata": {
        "id": "n71oiTMwX3gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test GD algorithm in the auto dataset alpha0 = -4, beta0 = 3\n",
        "alpha, beta, iterations = gradient_descent(auto['horsepower'],auto['high_price'], init = np.array([-4,0.1]))"
      ],
      "metadata": {
        "id": "h6mT7iQOYXWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Initial conditions alpha = -7 and beta = 0.01 implies {iterations} and best iterations coefficients alpha = {alpha:.6f} and beta = {beta:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5390e76-6fd8-439c-f1b6-02d2ef12c2bc",
        "id": "2DxR3D4LYXWF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial conditions alpha = -7 and beta = 0.01 implies 999.0 and best coefficients alpha = -4.004111 and beta = 0.030750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All tries achieved the maximum number of iterations and didn't move too far from the original values for the parameters and are far from each other. It suggests that we should increase the learning rate or the number of iterations of the algorithm as we pointed out above."
      ],
      "metadata": {
        "id": "LZl654InYgyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "In this lessor we learned:\n",
        "\n",
        "- The logistic regression is used for classification problems.\n",
        "- How it differs from the linear regression.\n",
        "- How the logit function links the probability of an outcome to a linear model.\n",
        "- There is no closed form to find the best parameters for the algorithm.\n",
        "- How the log-loss cost function is used to find the best parameters for the model.\n",
        "- How gradient descent allows one to find the optimal parameters for a logistic regression model."
      ],
      "metadata": {
        "id": "V93Sl_lVY_iX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2x76HEOawr2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}