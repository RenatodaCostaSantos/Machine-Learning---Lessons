{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqqS7yuM7bxN8Y1IKySCTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenatodaCostaSantos/Machine-Learning---Lessons/blob/main/Supervised%20ML/Logistic%20regression/Interpreting_logistic_regression_parameters_lesson_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Logistic regression is a classification model that can predict a binary or multiclass outcome, however, we will focus on binary classification in this lesson. Problems with a binary answer are common in practice. For example, predicting if a person is sick or healthy is common in logistic regression applications.\n",
        "\n",
        "In this lesson, we will learn how to interpret the coefficients of a logistic regression model.\n",
        "\n",
        "We will use the same auto dataset from from the previous lesson to exemplify the concepts using a real-world problem."
      ],
      "metadata": {
        "id": "l0MbErttcpEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YoiGxecfVa6",
        "outputId": "26141720-0d89-46a0-cecd-d0e15aafa194"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "auto = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/automobiles.csv')"
      ],
      "metadata": {
        "id": "pfUvY1Ibgj_F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "khwi8od7hEsx",
        "outputId": "4b91d869-9366-4262-da95-c9b84097351e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   symboling  normalized_losses  make fuel_type aspiration num_of_doors  \\\n",
              "0          2                164  audi       gas        std         four   \n",
              "1          2                164  audi       gas        std         four   \n",
              "2          1                158  audi       gas        std         four   \n",
              "3          1                158  audi       gas      turbo         four   \n",
              "4          2                192   bmw       gas        std          two   \n",
              "\n",
              "  body_style drive_wheels engine_location  wheel_base  ...  engine_size  \\\n",
              "0      sedan          fwd           front        99.8  ...          109   \n",
              "1      sedan          4wd           front        99.4  ...          136   \n",
              "2      sedan          fwd           front       105.8  ...          136   \n",
              "3      sedan          fwd           front       105.8  ...          131   \n",
              "4      sedan          rwd           front       101.2  ...          108   \n",
              "\n",
              "   fuel_system  bore  stroke compression_ratio horsepower  peak_rpm city_mpg  \\\n",
              "0         mpfi  3.19     3.4              10.0        102      5500       24   \n",
              "1         mpfi  3.19     3.4               8.0        115      5500       18   \n",
              "2         mpfi  3.19     3.4               8.5        110      5500       19   \n",
              "3         mpfi  3.13     3.4               8.3        140      5500       17   \n",
              "4         mpfi  3.50     2.8               8.8        101      5800       23   \n",
              "\n",
              "   highway_mpg  price  \n",
              "0           30  13950  \n",
              "1           22  17450  \n",
              "2           25  17710  \n",
              "3           20  23875  \n",
              "4           29  16430  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ea17def-a02b-44a5-9a85-3bcfe1f37dde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symboling</th>\n",
              "      <th>normalized_losses</th>\n",
              "      <th>make</th>\n",
              "      <th>fuel_type</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>num_of_doors</th>\n",
              "      <th>body_style</th>\n",
              "      <th>drive_wheels</th>\n",
              "      <th>engine_location</th>\n",
              "      <th>wheel_base</th>\n",
              "      <th>...</th>\n",
              "      <th>engine_size</th>\n",
              "      <th>fuel_system</th>\n",
              "      <th>bore</th>\n",
              "      <th>stroke</th>\n",
              "      <th>compression_ratio</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>peak_rpm</th>\n",
              "      <th>city_mpg</th>\n",
              "      <th>highway_mpg</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.8</td>\n",
              "      <td>...</td>\n",
              "      <td>109</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>102</td>\n",
              "      <td>5500</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>13950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>4wd</td>\n",
              "      <td>front</td>\n",
              "      <td>99.4</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>115</td>\n",
              "      <td>5500</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>17450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>105.8</td>\n",
              "      <td>...</td>\n",
              "      <td>136</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.19</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.5</td>\n",
              "      <td>110</td>\n",
              "      <td>5500</td>\n",
              "      <td>19</td>\n",
              "      <td>25</td>\n",
              "      <td>17710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>audi</td>\n",
              "      <td>gas</td>\n",
              "      <td>turbo</td>\n",
              "      <td>four</td>\n",
              "      <td>sedan</td>\n",
              "      <td>fwd</td>\n",
              "      <td>front</td>\n",
              "      <td>105.8</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.13</td>\n",
              "      <td>3.4</td>\n",
              "      <td>8.3</td>\n",
              "      <td>140</td>\n",
              "      <td>5500</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>23875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>192</td>\n",
              "      <td>bmw</td>\n",
              "      <td>gas</td>\n",
              "      <td>std</td>\n",
              "      <td>two</td>\n",
              "      <td>sedan</td>\n",
              "      <td>rwd</td>\n",
              "      <td>front</td>\n",
              "      <td>101.2</td>\n",
              "      <td>...</td>\n",
              "      <td>108</td>\n",
              "      <td>mpfi</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.8</td>\n",
              "      <td>8.8</td>\n",
              "      <td>101</td>\n",
              "      <td>5800</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>16430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ea17def-a02b-44a5-9a85-3bcfe1f37dde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ea17def-a02b-44a5-9a85-3bcfe1f37dde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ea17def-a02b-44a5-9a85-3bcfe1f37dde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will follow the same steps as the previous lesson and create a new binary column that contains values 0 for cars with price lower than $15,000 and 1 otherwise."
      ],
      "metadata": {
        "id": "4EQgkr7-hXSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create high_price column\n",
        "auto['high_price'] = 0\n",
        "auto.loc[auto['price'] > 15000, 'high_price'] = 1"
      ],
      "metadata": {
        "id": "7sUwdVKIh1cP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check new column values\n",
        "auto['high_price'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXmqaKJri_tP",
        "outputId": "85421d7c-8fd4-405b-c5b4-5cf919f79e04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    119\n",
              "1     40\n",
              "Name: high_price, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create features and target variables\n",
        "X = auto.drop(['high_price','price'], axis = 1)\n",
        "y = auto['high_price']"
      ],
      "metadata": {
        "id": "rm491MOxj3Hz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 712)"
      ],
      "metadata": {
        "id": "v1MP_YALkE0K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The logistic regression object\n",
        "\n",
        "To build a model we will use the sklearn logistic regression [class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). It can take many different parameters as one can see in the documentation. In this lesson we will use it to build a logistic regression model and use some of the attributes and methods of this class. \n",
        "\n",
        "We start by importing the LogisticRegression class from sklearn and build a model right away:"
      ],
      "metadata": {
        "id": "TBfgJ5PMkc7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instantiate a model\n",
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "M-ond3DLlpwU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There you go. We have a created model we can use to train and test the data. The model in this case is an object of the LogisticRegression class. It saves us all the time we spent on the previous lesson where we built it from scratch. The object we have in hands is much more powerful and efficient than the ones we created in the previous lesson, but now we have an idea of how it works under the hood.\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "We will follow similar steps as in the previous lesson and start using only the 'horsepower' feature to predict the outcomes for the 'high_price' target:\n"
      ],
      "metadata": {
        "id": "O9W-ZjoKmEPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a subset of the features\n",
        "X_sub = X_train[['horsepower']]\n",
        "# Fit the model\n",
        "model.fit(X_sub,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5taJet4mPCN",
        "outputId": "2f3630b1-0aff-400b-e502-754172594a2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done! We have a model that was trained with the 'horsepower' feature. As simple as that!\n",
        "\n",
        "Our goal is to interpret the coefficients of the model we just created. For that it is useful to remember the equation for the logistic regression model we derived in the last lecture:\n",
        "$$\n",
        "log(\\frac{EY}{1-EY}) = \\alpha + \\beta*X.\n",
        "$$\n",
        "\n",
        "In the linear regression model the coefficients are interpreted as the intercept and the slope of the line. However, in the logistic regression the predictors $X$ are not connected to the binary outcomes $y$, but to the log-odds of the success probability of obtaining an outcome $y$ (see the previous lesson notes if this sentence confuses you).\n",
        "\n",
        "To interpret the parameters, we can use a similar approach to the linear regression. First, when **a given predictor $X$** is null, we obtain:\n",
        " $$\n",
        "log(\\frac{EY}{1-EY}) = \\alpha.\n",
        "$$\n",
        "This tells us that the log-odds of the success probability of an outcome, for a given feature $X$, is equal to the $\\alpha$ parameter.\n",
        "\n",
        "Log-odds are hard to interpret, but the expression above provides an important step to start clarifying the meaning of the coefficients.\n",
        "\n",
        "In practice, one can easily obtain the intercept, $\\alpha$, for a logistic regression using sklearn by using the intercept attribute:"
      ],
      "metadata": {
        "id": "yhfjjFpApfbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the logistic regression intercept parameter\n",
        "alpha = model.intercept_\n",
        "print(model.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9w4lLw3q6MZ",
        "outputId": "fa18d3e9-8591-410d-fe3e-b363355413e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-8.97855833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Odds interpretation\n",
        "\n",
        "If we apply the exponential on both sides of the log-odds equation for the intercept, we obtain:\n",
        " $$\n",
        "Odds = \\frac{EY}{1-EY} = e^\\alpha.\n",
        "$$\n",
        "Odds are easier to interpret than log-odds. It gives the likelihood of obtaining a positive result over a negative one. In other words, if the odds are greater than 1, the probability of an event happening is greater than not happening. If it is less than 1 the conclusion is the opposite.\n",
        "\n",
        "Odds are useful when events happen many times. It tells us what to expect in the long run while the probability itself does not provide that information.\n",
        "\n",
        "Let's apply what we learned in the auto dataset by computing the odds of a car having a price higher than $15,000:\n"
      ],
      "metadata": {
        "id": "FY2RK0wxtHyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the odds of a car being higher than $15,000\n",
        "odds = np.exp(alpha)\n",
        "print(odds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxZgBdOlxCVD",
        "outputId": "4e85ac3f-c506-40c7-fd34-9156ddf89789"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00012608]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the odds of having a high price car with horsepower equal to zero is very close to zero, meaning, it is very unlikely.\n",
        "\n",
        "# Interpreting the slope\n",
        "\n",
        "To interpret the slope, $\\beta$ we subtract the value for the logistic model when the predictor $X = 0$: \n",
        "$$\n",
        "log(\\frac{EY(0)}{1-EY(0)}) = \\alpha,\n",
        "$$\n",
        "from the value when $X=1$:\n",
        "$$\n",
        "log(\\frac{EY(1)}{1-EY(1)}) = \\alpha + \\beta.\n",
        "$$\n",
        "The subtraction leads to:\n",
        "$$\n",
        "log(\\frac{Odds(1)}{Odds(0)}) = \\beta,\n",
        "$$\n",
        "where the argument of the log function above is called the **odds ratio**. It tells how much the odds ratio change if we change the predictor $X$ by one unit. We can rewrite the equation above as:\n",
        "$$\n",
        "\\frac{Odds(1)}{Odds(0)} = e^{\\beta}.\n",
        "$$\n",
        "If the odds ratio is greater than one, it implies that the probability of success $EY$ is increasing non-linearly with the predictors $X$ (that's because the odds depend on $EY$ and the odds ratio is equal to the exponential of $\\beta$ when $X$ goes from 0 to 1).\n",
        "\n",
        "Let's use the auto dataset to illustrate this point in practice. We use the coef_ attribute from the logistic regression class to obtain the slope $\\beta$:"
      ],
      "metadata": {
        "id": "oTk_t7DUx8Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving the slope from the logistic regression model\n",
        "beta = model.coef_"
      ],
      "metadata": {
        "id": "IZG1KjT3zLwE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the odds ratio\n",
        "odds_ratio = np.exp(beta)\n",
        "print(odds_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEVdWK08XFQm",
        "outputId": "926f49b0-3fcf-407e-ff3f-21902d196e4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.07991717]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The odds ratio for the model is greater than one. It means that the probability of success for a car with more horsepower increases exponentially. In other words, cars with more powerful engines are more likely to have a higher price.\n",
        "\n",
        "# Multiple predictors\n",
        "\n",
        "We have used only one feature to build the model above. Let's generalize it by including more features.\n",
        "\n",
        "The interpretation of the coefficients changes slightly in this case. The slope, for example, is interpreted as the change of the log of the odds ratio when we vary one of the predictors $X$ by a unit and keep the other predictors constant (a typical procedure when performing partial derivatives).\n",
        "\n",
        "Let's build a logistic regression model with multiple parameters and interpret it:"
      ],
      "metadata": {
        "id": "hyR74m4LXoYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a logistic model\n",
        "model2 = LogisticRegression()"
      ],
      "metadata": {
        "id": "D0N8JqW9YRVX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a subset of the features set\n",
        "X_subset = X_train[['horsepower','highway_mpg']]"
      ],
      "metadata": {
        "id": "p4_BWzObaILW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with the features above\n",
        "model2.fit(X_subset,y_train)\n",
        "# Get parameters\n",
        "oddsRatio_horsepower = np.exp(model2.coef_[0,0])\n",
        "oddsRatio_highway = np.exp(model2.coef_[0,1])\n",
        "\n",
        "print(f'The odds ratio for the horsepower variable is {oddsRatio_horsepower:.2f}.')\n",
        "print(f'The odds ratio for the highway_mpg variable is {oddsRatio_highway:.2f}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbtMFmBbahAm",
        "outputId": "1ad4d4da-6e68-43d0-dcd0-c0dd4189aa6e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The odds ratio for the horsepower variable is 1.04.\n",
            "The odds ratio for the highway_mpg variable is 0.73.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The odds ratio is greater than one for the horsepower variable when the highway_mpg is constant and less than one for the highway_mpg when the horsepower is constant. In other words:\n",
        "\n",
        "1- Cars with the same consumption per gallon but with more powerful engines are more likely to be more expensive and,\n",
        "\n",
        "2- Cars with the same horsepower but with higher petrol consumption are likely to be less expensive."
      ],
      "metadata": {
        "id": "9-G5lKwZbT-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Success probability\n",
        "\n",
        "The odds and odds ratio are much more useful than the success probability of an outcome itself. That's why we sidestepped the connection between the predictors $X$ and the success probability $EY$. However, one can still compute $EY$ with the mathematical expressions above. It is easy to show that:\n",
        "$$\n",
        "EY = \\frac{e^{\\alpha + \\beta*X}}{1 +e^{\\alpha + \\beta*X} }.\n",
        "$$\n",
        "\n",
        "There is no easy way to isolate the coefficients of the logistic regression in terms of the success probability $EY$. However, we can still compute it given a value for a predictor $X$.\n",
        "\n",
        "Scikitlearn provides a method to perform the calculation above more quickly via the [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) method.\n",
        "\n",
        "It is important to mention that an outcome could still be negative even if the probability of predicting it as positive is high. This is another reason why the odds and odds ratio are preferred. It informs how many positive and negative outcomes one would expect in a dataset.\n",
        "\n",
        "To illustrate how the predict_proba works, let's compute the predicted success probabilities for all the data points of the subset we defined above:\n"
      ],
      "metadata": {
        "id": "WWeURhXAbO3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Array containing all predicted probabilities for the outcomes of X_subset\n",
        "model2.predict_proba(X_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KDZo3uHgXeP",
        "outputId": "4c9ef3c5-d567-464b-83e9-ee3502faacd6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.64812456e-01, 8.35187544e-01],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [9.16053075e-01, 8.39469252e-02],\n",
              "       [9.96792251e-01, 3.20774860e-03],\n",
              "       [7.98588049e-01, 2.01411951e-01],\n",
              "       [4.25664094e-01, 5.74335906e-01],\n",
              "       [9.53188185e-01, 4.68118147e-02],\n",
              "       [9.43713718e-01, 5.62862825e-02],\n",
              "       [9.95623324e-01, 4.37667600e-03],\n",
              "       [2.69324022e-01, 7.30675978e-01],\n",
              "       [9.99754222e-01, 2.45777611e-04],\n",
              "       [8.04750559e-02, 9.19524944e-01],\n",
              "       [3.79219443e-01, 6.20780557e-01],\n",
              "       [7.98588049e-01, 2.01411951e-01],\n",
              "       [1.06784383e-01, 8.93215617e-01],\n",
              "       [5.71353216e-01, 4.28646784e-01],\n",
              "       [9.79540125e-01, 2.04598753e-02],\n",
              "       [9.99974398e-01, 2.56018410e-05],\n",
              "       [9.98740349e-01, 1.25965136e-03],\n",
              "       [9.99637902e-01, 3.62097743e-04],\n",
              "       [9.98740349e-01, 1.25965136e-03],\n",
              "       [6.08930337e-01, 3.91069663e-01],\n",
              "       [7.51094892e-01, 2.48905108e-01],\n",
              "       [7.18145022e-03, 9.92818550e-01],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [8.72310750e-01, 1.27689250e-01],\n",
              "       [9.63935082e-01, 3.60649183e-02],\n",
              "       [8.88845468e-01, 1.11154532e-01],\n",
              "       [9.98408504e-01, 1.59149586e-03],\n",
              "       [2.69324022e-01, 7.30675978e-01],\n",
              "       [2.39483965e-01, 7.60516035e-01],\n",
              "       [1.18341597e-02, 9.88165840e-01],\n",
              "       [2.40217647e-01, 7.59782353e-01],\n",
              "       [4.47576326e-02, 9.55242367e-01],\n",
              "       [9.81349423e-03, 9.90186506e-01],\n",
              "       [9.68935763e-01, 3.10642366e-02],\n",
              "       [5.71353216e-01, 4.28646784e-01],\n",
              "       [5.03836864e-01, 4.96163136e-01],\n",
              "       [9.56494705e-01, 4.35052950e-02],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [5.71353216e-01, 4.28646784e-01],\n",
              "       [9.97827267e-01, 2.17273256e-03],\n",
              "       [9.37072484e-01, 6.29275158e-02],\n",
              "       [8.63281674e-01, 1.36718326e-01],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [9.79540125e-01, 2.04598753e-02],\n",
              "       [9.92179529e-01, 7.82047124e-03],\n",
              "       [9.29903001e-01, 7.00969988e-02],\n",
              "       [9.63935082e-01, 3.60649183e-02],\n",
              "       [6.88382180e-01, 3.11617820e-01],\n",
              "       [6.96317582e-02, 9.30368242e-01],\n",
              "       [9.97827267e-01, 2.17273256e-03],\n",
              "       [8.22288619e-01, 1.77711381e-01],\n",
              "       [9.92179529e-01, 7.82047124e-03],\n",
              "       [9.92179529e-01, 7.82047124e-03],\n",
              "       [8.80825850e-01, 1.19174150e-01],\n",
              "       [4.35932899e-01, 5.64067101e-01],\n",
              "       [9.94030982e-01, 5.96901845e-03],\n",
              "       [9.99789810e-01, 2.10190212e-04],\n",
              "       [9.43553188e-01, 5.64468116e-02],\n",
              "       [8.54097703e-01, 1.45902297e-01],\n",
              "       [1.06784383e-01, 8.93215617e-01],\n",
              "       [4.44765836e-01, 5.55234164e-01],\n",
              "       [6.71692683e-01, 3.28307317e-01],\n",
              "       [9.91872154e-01, 8.12784576e-03],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [5.71353216e-01, 4.28646784e-01],\n",
              "       [9.49547287e-01, 5.04527128e-02],\n",
              "       [9.43713718e-01, 5.62862825e-02],\n",
              "       [9.99754222e-01, 2.45777611e-04],\n",
              "       [9.92179529e-01, 7.82047124e-03],\n",
              "       [9.92179529e-01, 7.82047124e-03],\n",
              "       [5.80490732e-02, 9.41950927e-01],\n",
              "       [5.80490732e-02, 9.41950927e-01],\n",
              "       [9.89347654e-01, 1.06523458e-02],\n",
              "       [9.72232209e-01, 2.77677909e-02],\n",
              "       [1.06688465e-01, 8.93311535e-01],\n",
              "       [3.84880595e-02, 9.61511941e-01],\n",
              "       [9.16053075e-01, 8.39469252e-02],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [9.43553188e-01, 5.64468116e-02],\n",
              "       [5.71106815e-01, 4.28893185e-01],\n",
              "       [8.04750559e-02, 9.19524944e-01],\n",
              "       [5.03836864e-01, 4.96163136e-01],\n",
              "       [6.08930337e-01, 3.91069663e-01],\n",
              "       [9.91872154e-01, 8.12784576e-03],\n",
              "       [3.43371290e-01, 6.56628710e-01],\n",
              "       [7.51094892e-01, 2.48905108e-01],\n",
              "       [1.14223615e-01, 8.85776385e-01],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [9.97827267e-01, 2.17273256e-03],\n",
              "       [6.63066535e-01, 3.36933465e-01],\n",
              "       [4.47576326e-02, 9.55242367e-01],\n",
              "       [6.08930337e-01, 3.91069663e-01],\n",
              "       [8.72310750e-01, 1.27689250e-01],\n",
              "       [9.27259377e-01, 7.27406225e-02],\n",
              "       [9.74305598e-01, 2.56944020e-02],\n",
              "       [4.25664094e-01, 5.74335906e-01],\n",
              "       [9.37072484e-01, 6.29275158e-02],\n",
              "       [9.79540125e-01, 2.04598753e-02],\n",
              "       [9.74305598e-01, 2.56944020e-02],\n",
              "       [9.98833262e-01, 1.16673837e-03],\n",
              "       [9.49547287e-01, 5.04527128e-02],\n",
              "       [9.37072484e-01, 6.29275158e-02],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [9.29903001e-01, 7.00969988e-02],\n",
              "       [9.72232209e-01, 2.77677909e-02],\n",
              "       [9.49547287e-01, 5.04527128e-02],\n",
              "       [9.41502832e-01, 5.84971683e-02],\n",
              "       [9.99976289e-01, 2.37112658e-05],\n",
              "       [6.44567428e-01, 3.55432572e-01],\n",
              "       [9.27259377e-01, 7.27406225e-02],\n",
              "       [9.74305598e-01, 2.56944020e-02],\n",
              "       [9.09879758e-01, 9.01202419e-02],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [2.69324022e-01, 7.30675978e-01],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [9.27259377e-01, 7.27406225e-02],\n",
              "       [9.74305598e-01, 2.56944020e-02],\n",
              "       [9.92482877e-01, 7.51712338e-03],\n",
              "       [6.97081738e-01, 3.02918262e-01],\n",
              "       [9.94480393e-01, 5.51960662e-03],\n",
              "       [2.69324022e-01, 7.30675978e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, it is much harder to quickly obtain useful information from the array above.\n",
        "\n",
        "# Summary\n",
        "\n",
        "In this lesson we learned:\n",
        "\n",
        "- How to isolate and interpret the coefficients of a logistic regression model in terms of the odds and odds ratio.\n",
        "\n",
        "- How to build a logistic regression model using sklearn.\n",
        "\n",
        "- How to retrieve the coefficients from the model.\n",
        "\n",
        "- How to use the predict_proba to calculate the success probability of every data in a dataset.\n",
        "\n",
        "- Why odds and odds ratio are preferred rather than the success probability when interpreting the coefficients of a logistic regression model."
      ],
      "metadata": {
        "id": "NrR1p2LCgdRf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Z5N6UMVh0Fl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}